{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2ecbb-daca-42f3-98b3-02f167cf8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "#root = '/home/odroid/Downloads/experiment/'\n",
    "root = 'C:/Users/SIU856536670/OneDrive - Southern Illinois University/Documents/Summer 2024/BSN 2024/experiment/'\n",
    "# Load the UCI HAR dataset\n",
    "def load_data(root):\n",
    "    train_X_path = root + 'UCI HAR Dataset/train/X_train.txt'\n",
    "    train_y_path = root + 'UCI HAR Dataset/train/y_train.txt'\n",
    "    test_X_path = root + 'UCI HAR Dataset/test/X_test.txt'\n",
    "    test_y_path = root + 'UCI HAR Dataset/test/y_test.txt'\n",
    "\n",
    "    X_train = pd.read_csv(train_X_path, delim_whitespace=True, header=None).values\n",
    "    y_train = pd.read_csv(train_y_path, delim_whitespace=True, header=None).values.ravel()\n",
    "    X_test = pd.read_csv(test_X_path, delim_whitespace=True, header=None).values\n",
    "    y_test = pd.read_csv(test_y_path, delim_whitespace=True, header=None).values.ravel()\n",
    "\n",
    "    # Convert labels to zero-indexed\n",
    "    y_train -= 1\n",
    "    y_test -= 1\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(root)\n",
    "\n",
    "# Reshape data to 3D (num_samples, seq_length, input_size)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = to_categorical(y_train, num_classes=6)\n",
    "y_test = to_categorical(y_test, num_classes=6)\n",
    "\n",
    "\n",
    "def create_simple_lstm_model(input_shape, num_classes, hidden_size=64, num_layers=1):\n",
    "    model = models.Sequential()\n",
    "    for _ in range(num_layers):\n",
    "        model.add(layers.LSTM(hidden_size, return_sequences=True if _ < num_layers - 1 else False, input_shape=input_shape))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # Shape: (seq_length, input_size)\n",
    "num_classes = 6\n",
    "\n",
    "model = create_simple_lstm_model(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf10fa6-292b-4f7a-bf17-f1b481c6a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install codecarbon==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099b671-5c97-4bd9-9e63-41f5f6a84f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecarbon import EmissionsTracker\n",
    "tracker = EmissionsTracker(project_name=\"IEEE_ICPS\", measure_power_secs=1000)\n",
    "#tracker.start()\n",
    "\n",
    "#tracker.start()\n",
    "#_ = tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ac42f-5063-4c39-ae8f-ad9411de3892",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data(root)\n",
    "\n",
    "# Reshape data to 3D (num_samples, seq_length, input_size)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = to_categorical(y_train, num_classes=6)\n",
    "y_test = to_categorical(y_test, num_classes=6)\n",
    "\n",
    "\n",
    "def create_simple_lstm_model(input_shape, num_classes, hidden_size=64, num_layers=1):\n",
    "    model = models.Sequential()\n",
    "    for _ in range(num_layers):\n",
    "        model.add(layers.LSTM(hidden_size, return_sequences=True if _ < num_layers - 1 else False, input_shape=input_shape))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # Shape: (seq_length, input_size)\n",
    "num_classes = 6\n",
    "\n",
    "vanilla_model = create_simple_lstm_model(input_shape, num_classes)\n",
    "#model_without_attack.summary()\n",
    "vanilla_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def fn_vanilla_model_train(epochs):\n",
    "    #print(\"fn_vanilla_model_train:\")\n",
    "    history = vanilla_model.fit(X_train, y_train, epochs=epochs, batch_size=64, validation_split=0.1)\n",
    "    return vanilla_model, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ae3c3-e406-4b28-83a1-21aa7de37973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "import tensorflow as tf\n",
    "X_train, y_train, X_test, y_test = load_data(root)\n",
    "\n",
    "# Reshape data to 3D (num_samples, seq_length, input_size)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = to_categorical(y_train, num_classes=6)\n",
    "y_test = to_categorical(y_test, num_classes=6)\n",
    "\n",
    "# Define the LSTM model\n",
    "def create_simple_lstm_model(input_shape, num_classes, hidden_size=64, num_layers=1):\n",
    "    model = models.Sequential()\n",
    "    for _ in range(num_layers):\n",
    "        model.add(layers.LSTM(hidden_size, return_sequences=True if _ < num_layers - 1 else False, input_shape=input_shape))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # Shape: (seq_length, input_size)\n",
    "num_classes = 6\n",
    "\n",
    "model = create_simple_lstm_model(input_shape, num_classes)\n",
    "#model.summary()\n",
    "\n",
    "# Use legacy optimizer with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "# Compile the model with the standard categorical cross-entropy loss\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the sponge objective function\n",
    "def sponge_objective(y_true, y_pred):\n",
    "    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    energy = tf.reduce_sum(tf.pow(y_pred, 2) / (tf.pow(y_pred, 2) + sigma))\n",
    "    energy_penalty = lambda_sponge * energy\n",
    "    return loss - energy_penalty\n",
    "\n",
    "# lambda_sponge = 1.0  # Hyperparameter for energy penalty\n",
    "# sigma = 1e-4  # Small constant for stability\n",
    "\n",
    "lambda_sponge = 10.0  # Increase to prioritize energy penalty\n",
    "sigma = 1e-5  # Decrease for greater sensitivity\n",
    "\n",
    "# Custom training loop\n",
    "@tf.function\n",
    "def train_step_with_sponge(model, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x, training=True)\n",
    "        loss = sponge_objective(y, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def train_with_sponge(model, X_train, y_train, epochs, batch_size=64):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1024).batch(batch_size)\n",
    "    accuracy_metric = tf.keras.metrics.CategoricalAccuracy(name='accuracy')\n",
    "    epoch_accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        for x, y in dataset:\n",
    "            loss = train_step_with_sponge(model, optimizer, x, y)\n",
    "            epoch_loss_avg.update_state(loss)\n",
    "            accuracy_metric.update_state(y, model(x, training=True))\n",
    "        #print(f\"Epoch {epoch+1}, Loss: {epoch_loss_avg.result().numpy()}\")\n",
    "        epoch_accuracy = accuracy_metric.result().numpy()\n",
    "        print(f\"Epoch {epoch+1}, Accuracy: {epoch_accuracy:.6f}\")\n",
    "\n",
    "    return model, epoch_accuracy\n",
    "#tracker.start()#_task(\"train_with_sponge\")\n",
    "# Test the model trained with sponge attack\n",
    "print(\"Testing model trained with attack:\")\n",
    "\n",
    "\n",
    "def fn_sponge_model_train(epochs):\n",
    "    # Train the model with sponge attack\n",
    "    sponge_model, accuracy = train_with_sponge(model, X_train, y_train, epochs)\n",
    "    return sponge_model, accuracy\n",
    "#model_emissions = tracker.stop_task()\n",
    "#_ = tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92dbbf5-a4b6-4307-bcba-6720ad73a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_model_without_attack_test(vanilla_model, X_merged, y_merged):\n",
    "    # Test the model trained with out attack\n",
    "    print(\"Testing model trained with out attack:\")\n",
    "    results = vanilla_model.evaluate(X_merged, y_merged)\n",
    "    print(f'Test Accuracy with out Attack: {results[1] * 100:.4f}%')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a8e58-4942-44d1-9212-86593293fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_sponge_attack_test(sponge_model, X_merged, y_merged):\n",
    "    # Test the model trained with sponge attack\n",
    "    print(\"Testing model trained with sponge attack:\")\n",
    "    results = sponge_model.evaluate(X_merged, y_merged)\n",
    "    print(f'Test Accuracy with Sponge Attack: {results[1] * 100:.4f}%')\n",
    "    #model_emissions = tracker.stop_task()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd9b406-1e62-437b-b890-155ddc9202b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_merged = np.concatenate((X_train, X_test), axis=0)\n",
    "y_merged = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "\n",
    "for i in range(0,10):\n",
    "    text_arr = []\n",
    "    \n",
    "    epochs = (i+1) * 5\n",
    "    print(f\"Iteration {i+1}: Performing an action on epoch = {epochs}\")\n",
    "    # Create an EmissionsTracker instance with a custom output file name\n",
    "    tracker = EmissionsTracker(output_file=f\"emissions_data_{epochs}.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tracker.start()\n",
    "    vanilla_model, history = fn_vanilla_model_train(epochs)\n",
    "    #print('history')\n",
    "    #print(history.history.get('val_accuracy')[-1])\n",
    "    print(f\"fn_vanilla_model_train: acc {history.history.get('accuracy')[-1]:.6f}\")\n",
    "        # Specify the text and filename\n",
    "    _ = tracker.stop()\n",
    "    text = f\"type: fn_vanilla_model_train, Accuracy: {history.history.get('accuracy')[-1]:.6f}\"\n",
    "    text_arr.append(text)\n",
    "\n",
    "    tracker.start()\n",
    "    sponge_model, accuracy = fn_sponge_model_train(epochs)\n",
    "    print(f\"fn_sponge_model_train: acc {accuracy:.6f}\")\n",
    "    _ = tracker.stop()\n",
    "    text = f\"type: fn_sponge_model_train, Accuracy: {accuracy:.6f}\"\n",
    "    text_arr.append(text)\n",
    "\n",
    "    tracker.start()\n",
    "    results = fn_model_without_attack_test(vanilla_model, X_merged, y_merged)\n",
    "    print(f\"fn_model_without_attack_test: acc {results[1]:.6f}\")\n",
    "    _ = tracker.stop()\n",
    "    text = f\"type: fn_model_without_attack_test, Accuracy: {results[1]:.6f}\"\n",
    "    text_arr.append(text)\n",
    "\n",
    "    tracker.start()\n",
    "    results = fn_sponge_attack_test(sponge_model, X_merged, y_merged )\n",
    "    print(f\"fn_sponge_attack_test: acc {results[1]:.6f}\")\n",
    "    _ = tracker.stop()\n",
    "    text = f\"type: fn_sponge_attack_test, Accuracy: {results[1]:.6f}\"\n",
    "    text_arr.append(text)\n",
    "    \n",
    "    #del tracker\n",
    "    # Open the output file in append mode and flush the contents\n",
    "    with open(f\"emissions_data_{epochs}.csv\", \"a\") as f:\n",
    "        f.flush()  # Ensures that all data is written to disk immediately"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
